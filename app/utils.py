import numpy as np
import pandas as pd
import time, os, json, requests
import boto3
from typing import List, Dict, Optional
from sklearn.preprocessing import MinMaxScaler
from pandas.errors import EmptyDataError


# S3 í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì „ì—­ìœ¼ë¡œ ë‘ë©´ ì„±ëŠ¥ ìµœì í™”)
S3_CLIENT = boto3.client('s3')


# ----------------------------------------------------------------------
# A. ì‹œí€€ìŠ¤ ìœˆë„ìš° ë³€í™˜ í•¨ìˆ˜ (ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ í•µì‹¬)
# ----------------------------------------------------------------------
def prepare_lstm_input(
    df_raw: pd.DataFrame, 
    scaler: MinMaxScaler, 
    sequence_length: int
) -> np.ndarray:
    """
    [ì±…ì„: LSTM ì…ë ¥ ë°ì´í„° ë³€í™˜]
    API ì…ë ¥ ë°ì´í„°(DataFrame)ë¥¼ ì •ê·œí™”í•˜ê³  LSTM ì¶”ë¡ ì— í•„ìš”í•œ 3D ì‹œí€€ìŠ¤ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        df_raw: ì¶”ë¡ ì— ì‚¬ìš©ë  íŠ¹ì§• ë°ì´í„° (Feature DataFrame).
        scaler: í›ˆë ¨ ì‹œ ì‚¬ìš©ëœ MinMaxScaler ê°ì²´.
        sequence_length: LSTM ìœˆë„ìš° í¬ê¸°.

    Returns:
        (1, sequence_length, n_features) í˜•íƒœì˜ 3D NumPy ë°°ì—´.
    """
    # 1. ë°ì´í„° íƒ€ì… ìœ íš¨ì„± ê²€ì‚¬ ë° ì •ê·œí™”
    if df_raw.empty:
        raise EmptyDataError("Input DataFrame is empty.")
    
    # í›ˆë ¨ ì‹œì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì •ê·œí™” (ì„±ëŠ¥ ìµœì í™”)
    try:
        data_scaled = scaler.transform(df_raw.values)
    except ValueError as e:
        # ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ ìˆ˜ ë¶ˆì¼ì¹˜ ë“±ì˜ ì˜¤ë¥˜ ë°©ì§€
        raise ValueError(f"Normalization failed: Input features mismatch. Original error: {e}")

    # 2. LSTM ì‹œí€€ìŠ¤ ìœˆë„ìš° ë³€í™˜ (í´ë¦° ì½”ë“œ: ë¡œì§ ë¶„ë¦¬)
    # schemas.pyì—ì„œ ì´ë¯¸ ê¸¸ì´ ê²€ì‚¬ë¥¼ í–ˆìœ¼ë‚˜, ë‚´ë¶€ ë¡œì§ ì•ˆì •ì„± í™•ë³´
    if data_scaled.shape[0] < sequence_length:
         raise ValueError(f"Insufficient data points ({data_scaled.shape[0]}) for sequence length {sequence_length}.")
        
    # ë§ˆì§€ë§‰ ìœˆë„ìš° ë§Œí¼ ìŠ¬ë¼ì´ì‹±í•˜ì—¬ 3D í˜•íƒœë¡œ ë³€í™˜
    X_inference = data_scaled[-sequence_length:].reshape(1, sequence_length, data_scaled.shape[1])
    
    return X_inference


# ----------------------------------------------------------------------
# B. API ì¸ì¦ ë° ë³´ì•ˆ í•¨ìˆ˜ (MLOps ë³´ì•ˆ)
# ----------------------------------------------------------------------
def authenticate_api_key(received_key: Optional[str], expected_key: str) -> bool:
    """
    API Keyë¥¼ ê²€ì¦í•˜ì—¬ ì¸ì¦ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not received_key:
        return False
        
    # MLOps ë³´ì•ˆ: í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œëœ í‚¤ì™€ ë¹„êµ
    return received_key == expected_key


# ----------------------------------------------------------------------
# C. ì•Œë¦¼ íŠ¸ë¦¬ê±° í•¨ìˆ˜ (MLOps ìë™í™”)
# ----------------------------------------------------------------------
def send_alert_notification(message: str, webhook_url: Optional[str]):
    """
    [ì±…ì„: ì™¸ë¶€ ì•Œë¦¼ ì „ì†¡]
    Slack Webhookì„ ì‚¬ìš©í•˜ì—¬ ë¶ˆëŸ‰ ê°ì§€ ê²½ê³  ì•Œë¦¼ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
    (ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” ë³„ë„ ë¹„ë™ê¸° ì‘ì—… íë¥¼ ì‚¬ìš©í•´ì•¼ ì„±ëŠ¥ì— ì˜í–¥ì´ ì—†ìŒ)
    """
    if not webhook_url:
        print("[WARNING] SLACK_WEBHOOK_URL is not set. Skipping notification.")
        return
        
    payload = {
        "text": f"ğŸš¨ [MELT TANK MLOPS ALERT] {message}",
        "username": "MeltingTank-AI-Monitor",
        "icon_emoji": ":warning:"
    }
    
    try:
        # ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” requests ëŒ€ì‹  asyncio/httpxë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬í•´ì•¼ 
        # API ì‘ë‹µ ì†ë„(Latency)ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤. (ì„±ëŠ¥ ìµœì í™” ì§€ì )
        response = requests.post(webhook_url, json=payload, timeout=5) # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        response.raise_for_status() 
        print(f"[INFO] Slack alert sent successfully at {time.strftime('%H:%M:%S')}")
    except requests.exceptions.Timeout:
        print(f"[ERROR] Slack alert failed: Request timed out.")
    except requests.exceptions.RequestException as e:
        print(f"[ERROR] Failed to send Slack alert: {e}")


# ----------------------------------------------------------------------
# D. ë¡œê¹… í•¨ìˆ˜ (MLOps ëª¨ë‹ˆí„°ë§) - ì‹¤ì œ êµ¬í˜„ ì‹œ DynamoDB/S3 ì—°ë™ í•„ìš”
# ----------------------------------------------------------------------
def log_prediction_result(
    input_data: List[Dict], 
    prob_ng: float, 
    label: str, 
    version: str,
    s3_bucket: str = os.getenv("S3_LOG_BUCKET"), 
    s3_prefix: str = os.getenv("S3_LOG_PREFIX", "melting_tank_logs")
):
    """
    [ì±…ì„: ì˜ˆì¸¡ ê²°ê³¼ ë¡œê¹…]
    ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë¡œê¹…í•©ë‹ˆë‹¤. ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œëŠ” DB/S3ì— ë¹„ë™ê¸° ì €ì¥í•©ë‹ˆë‹¤.
    """
    # [ìˆ˜ì •] pd.Timestamp.now() ì‚¬ìš©ì„ ìœ„í•´ pandas ì„í¬íŠ¸ í™•ì¸ (ì½”ë“œ ìµœìƒë‹¨ì—ì„œ ì²˜ë¦¬)
    import pandas as pd 
    
    log_entry = {
        "timestamp": pd.Timestamp.now().isoformat(),
        "model_version": version,
        "prediction_probability": prob_ng,
        "prediction_label": label,
        "input_summary": f"Data points: {len(input_data)}",
        # ìš´ì˜ ì‹œëŠ” ë°ì´í„° ìš©ëŸ‰ì„ ì¤„ì—¬ í•µì‹¬ ê°’ë§Œ ë¡œê¹…í•´ì•¼ í•©ë‹ˆë‹¤.
    }

    # S3 ì €ì¥ í˜¸ì¶œ
    if s3_bucket:
        log_data = { ... } # ìœ„ì—ì„œ ìƒì„±í•œ ìµœì¢… ë¡œê·¸ ë°ì´í„°
        save_log_to_s3(log_data, s3_bucket, s3_prefix, "inference")
    
    # í˜„ì¬ëŠ” ë‹¨ìˆœ ì½˜ì†” ì¶œë ¥ (ì‹¤ì œ ìš´ì˜ ì‹œ: Save to DynamoDB or S3)
    print(f"[LOG] Prediction recorded: {json.dumps(log_entry)}")


# ----------------------------------------------------------------------
# E. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ S3ì— JSON íŒŒì¼ë¡œ ì €ì¥
# ----------------------------------------------------------------------
def save_log_to_s3(log_data: dict, bucket_name: str, prefix: str, source: str):
    """
    ì˜ˆì¸¡ ê²°ê³¼ë¥¼ S3ì— JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. (ë¹„ë™ê¸° ì²˜ë¦¬ ê¶Œì¥)
    
    Args:
        log_data: ì €ì¥í•  ë¡œê·¸ ë°ì´í„° ë”•ì…”ë„ˆë¦¬.
        bucket_name: ëŒ€ìƒ S3 ë²„í‚· ì´ë¦„.
        prefix: ë²„í‚· ë‚´ ì €ì¥ ê²½ë¡œ ì ‘ë‘ì‚¬ (ì˜ˆ: logs/yyyy/mm/dd/).
    """
    # 1. íŒŒì¼ ì´ë¦„ ë° ê²½ë¡œ ì •ì˜ (ë°ì´í„° ì—”ì§€ë‹ˆì–´ë§ í‘œì¤€)
    # yyyy/mm/dd/source/timestamp.json í˜•íƒœë¡œ ì €ì¥í•˜ì—¬ Athena ë¶„ì„ ìš©ì´í•˜ê²Œ í•¨
    current_time = pd.Timestamp.now()
    timestamp_str = current_time.strftime("%Y%m%d%H%M%S")
    
    s3_key = (
        f"{prefix}/year={current_time.year}/month={current_time.month}/day={current_time.day}/"
        f"{source}_{timestamp_str}_{int(time.time()*1000)}.json"
    )
    
    # 2. JSON ì§ë ¬í™”
    json_data = json.dumps(log_data).encode('UTF-8')
    
    # 3. S3ì— ì—…ë¡œë“œ
    try:
        S3_CLIENT.put_object(
            Bucket=bucket_name,
            Key=s3_key,
            Body=json_data,
            ContentType='application/json'
        )
        print(f"[INFO] Log saved to S3: s3://{bucket_name}/{s3_key}")
    except Exception as e:
        # S3 ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„œë²„ ë‹¤ìš´ì„ ë§‰ê¸° ìœ„í•´ ì˜ˆì™¸ ì²˜ë¦¬
        print(f"[ERROR] Failed to save log to S3: {e}")